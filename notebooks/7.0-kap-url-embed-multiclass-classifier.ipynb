{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35414f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import redis\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import httpx\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from boilerpy3 import extractors\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.ru import Russian\n",
    "from nltk.corpus import wordnet as wn\n",
    "from textblob import TextBlob\n",
    "import tldextract\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import nltk\n",
    "from urllib.parse import urlparse\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import joblib\n",
    "from joblib import load\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "path = '/home/kalacheva/Desktop/'\n",
    "\n",
    "import pyppeteer\n",
    "from pyppeteer import launch \n",
    "from pyppeteer_stealth import stealth\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "import sys\n",
    "sys.path.append(path + 'utils.py')\n",
    "import utils\n",
    "from utils import (remove_tld, print_results, predict_url, \n",
    "predict_label, check, symbol_ngrams, url_train_data, \n",
    "to_train_embeddings, remove_trash, to_token, classify_web,\n",
    "url_text_classifier_transform, request_text_classifier_transform, ngram_classifier_transform, wait_request)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = SentenceTransformer('all-MPnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16edddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_categories = ['Internet and Telecom',\n",
    "'Arts and Entertainment',\n",
    "'Business and Industry',\n",
    "'Travel',\n",
    "'Health',\n",
    "'Games',\n",
    "'People and Society',\n",
    "'Finance',\n",
    "'Sports',\n",
    "'News and Media',\n",
    "'Career and Education',\n",
    "'Gambling',\n",
    "'Food and Drink',\n",
    "'Autos and Vehicles',\n",
    "'Law and Government',\n",
    "'Adult',\n",
    "'Reference',\n",
    "'Online Technologies',\n",
    "'Malicious webpages',\n",
    "'Shopping',\n",
    "'Advertising',\n",
    "'Info Security',\n",
    "'Real Estate',\n",
    "'Religion',\n",
    "'Alcohol and Tobacco',\n",
    "'Hosting and Sharing', \n",
    "'Organizations',\n",
    "'Meaningless Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea939aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Upload train and test datasets:\n",
    "\n",
    "# train_df = pd.read_csv(path + 'train.csv')\n",
    "# test_df = pd.read_csv(path + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caef3398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change url to get domain ('https://ya.ru/' -> 'ya.ru')\n",
    "\n",
    "# train_df['url'] = train_df['url'].apply(remove_tld)\n",
    "# test_df['url'] = test_df['url'].apply(remove_tld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f28e599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Divide data for train/test columns and labels:\n",
    "\n",
    "# X_train, y_train = train_df['url'], train_df['category']\n",
    "# X_test, y_test = test_df['url'], test_df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "998cf415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_dataset(category, directory_path, all_categories_df):\n",
    "    \n",
    "    print('Collecting category')\n",
    "    df_category = pd.read_csv(directory_path + f\"{category}.txt\", header=None, nrows=30000) \n",
    "    df_category = df_category[0].str.split(' ', expand=True)\n",
    "    df_category.loc[:, 'category'] = 1\n",
    "    \n",
    "    print('Collecting not_categry')\n",
    "    df_size = len(df_category)\n",
    "    df_not_category = all_categories_df.sample(df_size)\n",
    "    df_not_category = df_not_category.reset_index(drop=True)\n",
    "    \n",
    "    df_not_category['category'] = df_not_category['category'].apply(lambda x: 1 if x == f\"label_{category}\" else 0)    \n",
    "    \n",
    "    print('Making one dataset')\n",
    "    df_not_category.columns = df_category.columns\n",
    "    df = pd.concat([df_category.reset_index(drop=True), df_not_category.reset_index(drop=True)], axis=0, ignore_index=True)\n",
    "    \n",
    "    print('Mixing dataset')\n",
    "    df = df.sample(frac=1, random_state=42, ignore_index=True)\n",
    "    \n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(f\"Length of train_df: {len(train_df)}, lenght of test: {len(test_df)}\")\n",
    "    \n",
    "    return train_df, test_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f47365f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 28/28 [00:03<00:00,  7.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# directory = \"/home/kalacheva/Desktop/new/\"\n",
    "\n",
    "# all_categories_df = pd.DataFrame(columns=range(0, 769))\n",
    "\n",
    "# for label in tqdm(final_categories):  \n",
    "#     file_path = os.path.join(directory, f\"{label}.txt\")\n",
    "\n",
    "#     data = np.loadtxt(file_path, max_rows=750)  \n",
    "#     label_df = pd.DataFrame(data)\n",
    "#     label_df[\"category\"] = f\"label_{label}\"\n",
    "# #     print(label_df.shape, all_categories_df.shape)\n",
    "# #     all_categories_df.loc[len(all_categories_df)] = label_df\n",
    "#     all_categories_df = pd.concat([all_categories_df, pd.DataFrame(label_df)], ignore_index=True)\n",
    "# all_categories_df = all_categories_df.drop(all_categories_df.columns[768], axis=1)\n",
    "# all_categories_df.to_csv('/home/kalacheva/Desktop/all_categories_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "667eb4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model(category, save_path, directory_path, all_categories_df):\n",
    "    \n",
    "    print(f\"Start training for {category} category\")\n",
    " \n",
    "    train_df_filtered, test_df_filtered = category_dataset(category, directory_path, all_categories_df)\n",
    "\n",
    "    X_train, y_train = train_df_filtered.iloc[:, :-1], train_df_filtered['category'].astype('int') \n",
    "    X_test, y_test = test_df_filtered.iloc[:, :-1], test_df_filtered['category'].astype('int') \n",
    "\n",
    "    classifier = LGBMClassifier()\n",
    "    classifier.fit(X_train.astype('float'), y_train.astype('int'))\n",
    "    y_pred = classifier.predict(X_test.astype('float'))\n",
    "    score = accuracy_score(y_test.astype('int'), y_pred)\n",
    "    print(f\"Score: {score}\")\n",
    " \n",
    "    \n",
    "    joblib.dump(classifier, save_path + category + '.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e6e300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_categories_df = pd.read_csv(path + 'all_categories_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "849dbe8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for Internet and Telecom category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.852\n",
      "Start training for Arts and Entertainment category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.75025\n",
      "Start training for Business and Industry category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.84775\n",
      "Start training for Travel category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.795\n",
      "Start training for Health category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.824375\n",
      "Start training for Games category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.82625\n",
      "Start training for People and Society category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.840375\n",
      "Start training for Finance category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.8975\n",
      "Start training for Sports category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.76025\n",
      "Start training for News and Media category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.76875\n",
      "Start training for Career and Education category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.818\n",
      "Start training for Gambling category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 10089, lenght of test: 2523\n",
      "Score: 0.8172810146650813\n",
      "Start training for Food and Drink category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 25182, lenght of test: 6296\n",
      "Score: 0.8027318932655655\n",
      "Start training for Autos and Vehicles category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.799125\n",
      "Start training for Law and Government category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.83875\n",
      "Start training for Adult category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.77325\n",
      "Start training for Reference category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.744625\n",
      "Start training for Online Technologies category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.90625\n",
      "Start training for Malicious webpages category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.797625\n",
      "Start training for Shopping category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.859875\n",
      "Start training for Advertising category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.94975\n",
      "Start training for Info Security category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 13187, lenght of test: 3297\n",
      "Score: 0.8817106460418562\n",
      "Start training for Real Estate category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 28939, lenght of test: 7235\n",
      "Score: 0.803317208016586\n",
      "Start training for Religion category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 26572, lenght of test: 6644\n",
      "Score: 0.8093016255267911\n",
      "Start training for Alcohol and Tobacco category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 5417, lenght of test: 1355\n",
      "Score: 0.8014760147601476\n",
      "Start training for Hosting and Sharing category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.8565\n",
      "Start training for Organizations category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 29420, lenght of test: 7356\n",
      "Score: 0.8034257748776509\n",
      "Start training for Meaningless Content category\n",
      "Collecting category\n",
      "Collecting not_categry\n",
      "Making one dataset\n",
      "Mixing dataset\n",
      "Length of train_df: 32000, lenght of test: 8000\n",
      "Score: 0.896625\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "for i in final_categories:\n",
    "    train_and_save_model(i, '/home/kalacheva/Desktop/url_models/', '/home/kalacheva/Desktop/url_embeddings/', all_categories_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
